{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Corpus\n",
    "\n",
    "Corpus from: https://dumps.wikimedia.org/dewiki/20200820/\n",
    "\n",
    "Sentences for comparison from: https://github.com/t-systems-on-site-services-gmbh/german-wikipedia-text-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from xml.etree.ElementTree import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import os\n",
    "import pprint\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import LdaMulticore\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from smart_open import open \n",
    "import spacy\n",
    "import de_core_news_md\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the XML-file\n",
    "xml_file = \"/data/dewiki-20200820-pages-articles-multistream.xml\"\n",
    "\n",
    "# number of documents to parse \n",
    "num_documents = 200\n",
    "\n",
    "# similarity threshold, when does a document count as plagiarism\n",
    "sim_threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to return the title of a given article later on, we need to store those in a dictionary:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "title_ids = get_titles(xml_file, num_documents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save the index\n",
    "pickle_out = open(\"data/title_ids200.pickle\", \"wb\")\n",
    "pickle.dump(title_ids, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the index from disk\n",
    "title_ids = pickle.load(open(\"data/title_ids200.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a corpus from the text contents of the XML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Corpus is defined as a class object, so it can be called when needed.\n",
    "2. Loops through the XML-file, searching for closing \"text\" tags.\n",
    "3. Returns the text contents from these nodes in preprocessed form.\n",
    "4. Then clears the current node from memory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define the corpus as an object\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        # define the XML tree\n",
    "        for event, elem in ET.iterparse(xml_file, events = (\"start\", \"end\")):            \n",
    "            # Each document is represented as an object between <text> tags in the xml file\n",
    "            if event == 'end' and \"text\" in elem.tag:\n",
    "                # Transfom the corpus to vectors\n",
    "                yield dictionary.doc2bow(preprocess_text(elem.text))\n",
    "                # clear the node\n",
    "                elem.clear()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the corpus, without loading it into memory, this is not needed when working with the smaller corpus."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corpus = MyCorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole corpus is too big for this experiment and takes too long to parse through. For our proof-of-concept approach we therefore propose a function which only loops through the first i documents (text nodes) in the XML tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a smaller corpus, containing only the first i documents:\n",
    "class MyCorpus_small:\n",
    "    def __iter__(self):\n",
    "        index = 0\n",
    "        # define the XML tree\n",
    "        for event, elem in ET.iterparse(xml_file, events = (\"start\", \"end\")):\n",
    "            if index < num_documents:\n",
    "                # Each document is represented as an object between <text> tags in the xml file\n",
    "                if event == 'end' and \"text\" in elem.tag:\n",
    "                    # Transfom the corpus to vectors\n",
    "                    yield dictionary.doc2bow(preprocess_text(elem.text))\n",
    "                    index+=1\n",
    "                    # clear the node\n",
    "                    elem.clear()\n",
    "            else:\n",
    "                break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the smaller corpus, again without loading it into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_small = MyCorpus_small()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Dictionary\n",
    "\n",
    "To further work with the corpus in vector form, we need to build a dictionary. \n",
    "\n",
    "This function needs to be called only once, since we are able to save the dictionary created by it and load it in future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DO NOT RUN THE FOLLOWING CODE IF THE DICTIONARY CAN BE LOADED FROM A FILE__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# build the dictionary:\n",
    "dictionary = build_dictionary(xml_file, num_documents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# remove words that appear only once\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]\n",
    "dictionary.filter_tokens(once_ids)\n",
    "# remove gaps in id sequence after words that were removed\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save the dictionary\n",
    "dictionary.save('data/wiki_200_new.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CONTINUE HERE TO LOAD THE DICTIONARY__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dictionary\n",
    "dictionary = Dictionary.load('data/wiki_200_new.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(20308 unique tokens: ['abc', 'abkehr', 'ablehnen', 'abrufen', 'abschluss']...)\n"
     ]
    }
   ],
   "source": [
    "# check if the dictionary has been loaded \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity with LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "* corpus: the corpus\n",
    "* num_topics: topics to be extracted from the training corpus\n",
    "* id2word: id to word mapping, the dictionary\n",
    "* workers: number of cpu cores used\n",
    "\n",
    "The trained model can be stored and loaded, as same as the dictionary before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define document to use in similarity check\n",
    "test_document = open('beispieltexte/AlPacino.txt', encoding='utf-8')\n",
    "document_name = '\"'+os.path.basename(test_document.name)+'\"'\n",
    "test_document = test_document.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudo funktion zum errechnen der richtigen topic zahl \n",
    "topics = int(len(test_document)/(23000/len(test_document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 57s, sys: 24.9 s, total: 5min 22s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LdaMulticore(corpus_small, num_topics=topics, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=20308, num_topics=1089, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First experiments have shown that a topic number of 10 (default) is too low. 100 resulted in better disctinction between the different articles.\n",
    "__Further fine tuning needed here__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save the trained model\n",
    "lda.save(\"data/lda_model_200_t300.txt\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#load the trained model\n",
    "lda = LdaModel.load(\"data/lda_model_200_t300.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index the corpus with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 3min 4s, total: 6min 4s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_index = similarities.MatrixSimilarity(list(model[corpus_small]), num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save the index\n",
    "pickle_out = open(\"data/lda_index_200_t300.pickle\", \"wb\")\n",
    "pickle.dump(corpus_index, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load the index from disk\n",
    "corpus_index = pickle.load(open(\"data/lda_index_200_t300.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Check\n",
    "\n",
    "Now that we have a LDA model and an index we can check the similarity of an input document against all documents in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gegenüber seinen Rivalen Aldi Süd und Lidl drohte Aldi Nord immer weiter zurückzufallen. „Viele Jahre hatte der Discounter zu wenig in die Modernisierung investiert und zu spät auf neue Trends reagiert.“[30] Daher führte die Aldi-Nord-Gruppe mit dem Aldi Nord Instore Konzept (ANIKo) ebenfalls ein „Modernisierungsprogramm“ durch. Insgesamt wurde die bis Anfang 2019 vorgesehene Umgestaltung der 2250 Aldi-Nord-Filialen auf 5,2 Milliarden Euro kalkuliert. Im Anschluss erfolgte die Umgestaltung der rund 2400 Märkte im europäischen Ausland. Da keine expliziten Kostensenkungsprogramme bekannt sind, werden nach Beobachtern die Umbaukosten nur durch den später erwarteten höheren Umsatz wieder ausgeglichen.[31] Das Standardsortiment von Aldi Nord lag im Geschäftsjahr 2017 bei rund 1400 Artikeln. Der Test mit diesen Albrecht-Supermärkten scheiterte, da er weder in den Ladengrößen noch in der Sortimentsvielfalt der inzwischen davongeeilten Vollsortimenter-Konkurrenz ebenbürtig war. Diese noch unter dem roten Albrecht-Logo getesteten Märkte wurden bald wieder geschlossen bzw. konnten kurze Zeit später nach Umgestaltung auf Aldi-Discount genutzt werden. Die beiden Unternehmensgruppen sind freundschaftlich verbunden und koordinieren im Aldi-Unternehmensausschuss gemeinsam ihre Geschäftspolitik. Das Bundeskartellamt[43] betrachtet Aldi Nord und Aldi Süd als „faktischen Gleichordnungskonzern“ im Sinne von § 18 Abs. 2 Aktiengesetz (Deutschland). Rechtlich, organisatorisch und seit 1966 auch finanziell sind beide Unternehmensgruppen völlig unabhängig voneinander. In Deutschland umfassen Aldi Nord und Aldi Süd zusammen 66 Regionalgesellschaften, die wiederum ca. 4250 Aldi-Filialen kontrollieren (Stand: April 2015). Die Regionalgesellschaften haben ihren Sitz oft außerhalb der größeren Ballungszentren; sie liegen meist nahe einem Autobahnanschluss, um die Effizienz der Belieferung der Filialen per Lkw zu erhöhen. \n",
      "\n",
      "Alfredo James „Al“ Pacino (* 25. April 1940 in New York) ist ein US-amerikanischer Schauspieler, Filmregisseur und Filmproduzent. Er gilt für viele Kritiker und Zuschauer als einer der herausragenden Charakterdarsteller des zeitgenössischen amerikanischen Films und Theaters. So ist er seit den 1970er Jahren in zahlreichen Filmklassikern zu sehen.\n",
      "m Laufe seiner Karriere wurde er unter anderem mit dem Oscar, dem Golden Globe Award, dem Tony Award und der National Medal of Arts ausgezeichnet. Seine bekanntesten Rollen sind die des Michael Corleone in der von Francis Ford Coppola inszenierten Der Pate-Trilogie und als Gangster Tony Montana in Scarface.\n",
      "Pacino interessierte sich schon als Kind für die Schauspielerei. Er verfeinerte sein Talent an zwei renommierten New Yorker Schauspielschulen, in Herbert Berghofs HB Studio und später bei Lee Strasberg im The Actors Studio. Dort spielte er in mehreren erfolgreichen Theaterstücken wie in seinem Debütstück The Connection und in The Indian Wants the Bronx, für das er mit einem Obie-Award ausgezeichnet wurde.\n",
      "Al Pacino war insgesamt neun Mal für einen Oscar nominiert. Seine erste Nominierung erhielt er 1973 für seine Rolle des Michael Corleone in Der Pate von Francis Ford Coppola. \n",
      "Angelina Jolie (* 4. Juni 1975 als Angelina Jolie Voight in Los Angeles, Kalifornien) ist eine US-amerikanisch-kambodschanische Schauspielerin, Filmregisseurin, Filmproduzentin und Drehbuchautorin. Während ihrer Ehe mit Brad Pitt trug sie den Namen Angelina Jolie Pitt.\n",
      "Sie wurde mit der Darstellung der Videospielheldin Lara Croft in Lara Croft: Tomb Raider (2001) international bekannt. \n",
      "\n",
      "\n",
      "Angela Merkel (2019) Merkels Unterschrift\n",
      "Angela[1] Dorothea Merkel (geb. Kasner;[2] * 17. Juli 1954 in Hamburg) ist eine deutsche Politikerin (CDU). Sie ist seit dem 22. November 2005 Bundeskanzlerin der Bundesrepublik Deutschland. Vom 10. April 2000 bis zum 7. Dezember 2018 war sie CDU-Bundesvorsitzende.\n",
      "\n",
      "Merkel wuchs in der DDR auf und war dort als Physikerin am Zentralinstitut für Physikalische Chemie tätig. Bei der Bundestagswahl am 2. Dezember 1990 errang sie erstmals ein Bundestagsmandat. Bei den folgenden sieben Bundestagswahlen wurde sie in ihrem Wahlkreis in Vorpommern direkt gewählt.[3] Von 1991 bis 1994 war Merkel Bundesministerin für Frauen und Jugend im Kabinett Kohl IV und von 1994 bis 1998 Bundesministerin für Umwelt, Naturschutz und Reaktorsicherheit im Kabinett Kohl V. 1998 bis zu ihrer Wahl zur Bundesvorsitzenden der Partei amtierte sie als Generalsekretärin der CDU.\n",
      "\n",
      "Nach dem knappen Sieg der Unionsparteien bei der vorgezogenen Bundestagswahl 2005 löste Merkel Gerhard Schröder als Bundeskanzler ab und führte zunächst eine große Koalition mit der SPD bis 2009 (Kabinett Merkel I). Nach der Bundestagswahl 2009 ging sie mit der FDP eine schwarz-gelbe Koalition ein (Kabinett Merkel II), der 2013 eine erneute große Koalition folgte, die auch nach der Bundestagswahl 2017 fortgesetzt wird (Kabinett Merkel III und IV). Am 29. Oktober 2018 gab sie bekannt, zur Bundestagswahl 2021 nicht mehr zu kandidieren.[4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform the document to vector space\n",
    "test_vec = dictionary.doc2bow(preprocess_text(test_document))\n",
    "# convert to lda space\n",
    "test_vec_lda = model[test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the similarities\n",
    "sims = corpus_index[test_vec_lda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "hits = 0\n",
    "hit_title =[]\n",
    "for ids in list(enumerate(sims)):\n",
    "    if ids[1] >= sim_threshold and \"Liste von Autoren\" not in title_ids.get(ids[0]):\n",
    "        hits += 1\n",
    "        title = title_ids.get(ids[0])\n",
    "        hit_title.append(title)\n",
    "        print(\"Similarity Score: \",ids[1],\"\\n\",\"Document ID:\",ids[0],\"\\n\",\"Title:\", title,\"\\n\", \"------------------------------------\")\n",
    "print(hits, \"cases of possible plagiarism detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates result tags for html output\n",
    "result_html = \"\"\n",
    "cr_level =\"\"\n",
    "hits = 0\n",
    "for ids in list(enumerate(sims)):\n",
    "    if ids[1] >= sim_threshold and \"Liste von Autoren\" not in title_ids.get(ids[0]):\n",
    "        hits += 1\n",
    "        title = title_ids.get(ids[0])\n",
    "\n",
    "        if ids[1] < 0.5:\n",
    "            cr_level=\"zero\"\n",
    "        if ids[1] >= 0.6:\n",
    "            cr_level=\"low\"\n",
    "        if ids[1] >= 0.7:\n",
    "            cr_level=\"medium\"\n",
    "        if ids[1] >= 0.8:\n",
    "            cr_level=\"higher\"\n",
    "        if ids[1] >= 0.9:\n",
    "            cr_level=\"high\"\n",
    "        result_html = result_html+\" <tr class='\"+cr_level+\"'><td><a href='https://de.wikipedia.org/wiki/\"+title+\"'>\"+title+\"</a></td> \"+\"<td>\"+str(round(ids[1],2))+\"</td> \"+\"<td>\"+str(ids[0])+\"</td> </tr> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".r_table {\n",
       "  font-family: Arial;\n",
       "  border-collapse: collapse;\n",
       "  width: 100%;}\n",
       "  \n",
       ".r_table th {border: 1px solid #ddd;padding: 8px;}\n",
       "\n",
       ".r_table th {\n",
       "  font-size: 16px;\n",
       "  padding-top: 12px;\n",
       "  padding-bottom: 12px;\n",
       "  text-align: left;\n",
       "  background-color: steelblue;\n",
       "  color: white;\n",
       "  border: 1px solid #ddd;}\n",
       "  \n",
       ".r_table td {border: 1px solid #ddd;font-size: 14px; text-align:left;}\n",
       "\n",
       ".high td{background-color: #F8E0E0;}\n",
       ".higher td{background-color: #F8ECE0;}\n",
       ".medium td{background-color: #F7F8E0;}\n",
       ".low td{background-color: #E0F8E0;}\n",
       ".zero td{background-color: white;}\n",
       "</style>\n",
       "\n",
       "<h3> The tested input \"btext2.txt\" has the following similarity results </h3> \n",
       "<table class=\"r_table\">\n",
       "  <tr>\n",
       "    <th>Document Title</th>\n",
       "    <th>Similarity Score</th> \n",
       "    <th>Document-ID</th>\n",
       "  </tr>\n",
       "   <tr class='low'><td><a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></td> <td>0.61</td> <td>47</td> </tr>  <tr class='zero'><td><a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></td> <td>0.42</td> <td>82</td> </tr>  <tr class='zero'><td><a href='https://de.wikipedia.org/wiki/Angela Merkel'>Angela Merkel</a></td> <td>0.52</td> <td>89</td> </tr>  <tr class='zero'><td><a href='https://de.wikipedia.org/wiki/Adolf Hitler'>Adolf Hitler</a></td> <td>0.38</td> <td>122</td> </tr>  <tr class='zero'><td><a href='https://de.wikipedia.org/wiki/Ampelkoalition'>Ampelkoalition</a></td> <td>0.21</td> <td>126</td> </tr>  <tr class='zero'><td><a href='https://de.wikipedia.org/wiki/Aldi'>Aldi</a></td> <td>0.48</td> <td>180</td> </tr> \n",
       "\n",
       "</table>\n",
       "<h4>6 wikipedia documents with higher similarity found</h4> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# html output of all results\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".r_table {\n",
    "  font-family: Arial;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;}\n",
    "  \n",
    ".r_table th {border: 1px solid #ddd;padding: 8px;}\n",
    "\n",
    ".r_table th {\n",
    "  font-size: 16px;\n",
    "  padding-top: 12px;\n",
    "  padding-bottom: 12px;\n",
    "  text-align: left;\n",
    "  background-color: steelblue;\n",
    "  color: white;\n",
    "  border: 1px solid #ddd;}\n",
    "  \n",
    ".r_table td {border: 1px solid #ddd;font-size: 14px; text-align:left;}\n",
    "\n",
    ".high td{background-color: #F8E0E0;}\n",
    ".higher td{background-color: #F8ECE0;}\n",
    ".medium td{background-color: #F7F8E0;}\n",
    ".low td{background-color: #E0F8E0;}\n",
    ".zero td{background-color: white;}\n",
    "</style>\n",
    "\n",
    "<h3> The tested input \"\"\"+document_name+\"\"\" has the following similarity results </h3> \n",
    "<table class=\"r_table\">\n",
    "  <tr>\n",
    "    <th>Document Title</th>\n",
    "    <th>Similarity Score</th> \n",
    "    <th>Document-ID</th>\n",
    "  </tr>\n",
    "  \"\"\"+result_html+\"\"\"\n",
    "\n",
    "</table>\n",
    "<h4>\"\"\"+str(hits)+\"\"\" wikipedia documents with higher similarity found</h4> \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Al Pacino',\n",
       " 'Angelina Jolie',\n",
       " 'Angela Merkel',\n",
       " 'Adolf Hitler',\n",
       " 'Ampelkoalition',\n",
       " 'Aldi']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_ids = {}\n",
    "hit_title =[]\n",
    "for ids in list(enumerate(sims)):\n",
    "    if ids[1] >= sim_threshold and \"Liste von Autoren\" not in title_ids.get(ids[0]):\n",
    "        hit_ids[ids[0]] = ids[1]\n",
    "        hit_title.append(title_ids.get(ids[0]))\n",
    "hit_ids\n",
    "hit_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Similarity\n",
    "\n",
    "The next step would be to define all documents that were found to have a specific similarity score as a new corpus. Then we can check the similarty score for each sentence from the input document in relation to the sentences from the \"new\" corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 1.97 s, total: 17.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = 0\n",
    "first_elem = True\n",
    "# loop through all nodes\n",
    "for event, elem in ET.iterparse(xml_file, events = (\"start\", \"end\")):        \n",
    "    if index < num_documents:\n",
    "        # check if current node contains a document\n",
    "        if event == \"end\" and \"text\" in elem.tag:\n",
    "            if index in hit_ids.keys():\n",
    "                # preprocess the text\n",
    "                text = preprocess_text(elem.text)\n",
    "                # if this is the first document found, create a new dictionary with it\n",
    "                if first_elem:\n",
    "                    dictionary_hits = Dictionary([text])\n",
    "                    first_elem = False\n",
    "                    index += 1\n",
    "                # all documents after the first one get appended to the dictionary\n",
    "                else:\n",
    "                    dictionary_hits.add_documents([text])\n",
    "                    index += 1\n",
    "                # clear the node\n",
    "                elem.clear()\n",
    "                \n",
    "            else:\n",
    "                index += 1\n",
    "                elem.clear()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11651"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a smaller corpus, containing only the first i documents:\n",
    "class MyCorpus_small_hits:\n",
    "    def __iter__(self):\n",
    "        index = 0\n",
    "        # define the XML tree\n",
    "        for event, elem in ET.iterparse(xml_file, events = (\"start\", \"end\")):\n",
    "            if index < num_documents:\n",
    "                if index in hit_ids.keys():\n",
    "                    # Each document is represented as an object between <text> tags in the xml file\n",
    "                    if event == 'end' and \"text\" in elem.tag:\n",
    "                        # Transfom the corpus to vectors\n",
    "                        yield dictionary_hits.doc2bow(preprocess_text(elem.text))\n",
    "                        index+=1\n",
    "                        # clear the node\n",
    "                        elem.clear()\n",
    "                else:\n",
    "                    index+=1  \n",
    "            else:\n",
    "                break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_small_hits = MyCorpus_small_hits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudo funktion zum errechnen der richtigen topic zahl \n",
    "topics_hit = int(len(test_document)/(56000/len(test_document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 981 ms, total: 5.98 s\n",
      "Wall time: 5.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_model = LdaMulticore(corpus_small_hits, num_topics=topics_hit, id2word=dictionary_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x153de9d30>\n"
     ]
    }
   ],
   "source": [
    "print(termsim_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 3.09 s, total: 5.53 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_hit_index = similarities.MatrixSimilarity(list(hit_model[corpus_small_hits]), num_features=len(dictionary_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<6 docs, 11651 features>\n"
     ]
    }
   ],
   "source": [
    "print(corpus_hit_index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#use spacy to slice sentences\n",
    "#slice test document to sentences\n",
    "test_doc_raw_slice = []\n",
    "for split in spacy_data(test_document).sents:\n",
    "    test_doc_raw_slice.append(word_tokenize(str(split)))\n",
    "\n",
    "test_doc_raw_sentence = []\n",
    "for split in spacy_data(test_document).sents:\n",
    "    test_doc_raw_sentence.append(str(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nltk tokenize to slice sentences\n",
    "from nltk import tokenize\n",
    "\n",
    "#slice test document to sentences\n",
    "test_doc_raw_slice = []\n",
    "for split in tokenize.sent_tokenize(test_document):\n",
    "    test_doc_raw_slice.append(preprocess_text(str(split)))\n",
    "\n",
    "test_doc_raw_sentence = []\n",
    "for split in tokenize.sent_tokenize(test_document):\n",
    "    test_doc_raw_sentence.append(str(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_hits = []\n",
    "for sentence in test_doc_raw_slice:\n",
    "    # test doc Sätze vs hit_corpus \n",
    "    test_vec = dictionary_hits.doc2bow(sentence)\n",
    "    # convert to lda space\n",
    "    test_vec_lda = hit_model[test_vec]\n",
    "    sim_hits.append(corpus_hit_index[test_vec_lda])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Anschluss erfolgte die Umgestaltung der rund 2400 Märkte im europäischen Ausland.\n",
      "aus Dokument:  Angela Merkel\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.0146749  1. 1. 0.02761932 0.]\n",
      "max:  1.0 position:  2\n",
      "----------------------------------------------\n",
      "Diese noch unter dem roten Albrecht-Logo getesteten Märkte wurden bald wieder geschlossen bzw.\n",
      "aus Dokument:  Ampelkoalition\n",
      "Übereinstimmung:  0.99920845\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0. 0. 0. 0.99920845 0.]\n",
      "max:  0.99920845 position:  4\n",
      "----------------------------------------------\n",
      "konnten kurze Zeit später nach Umgestaltung auf Aldi-Discount genutzt werden.\n",
      "aus Dokument:  Angela Merkel\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.0146749  1. 1. 0.02761932 0.]\n",
      "max:  1.0 position:  2\n",
      "----------------------------------------------\n",
      "Die beiden Unternehmensgruppen sind freundschaftlich verbunden und koordinieren im Aldi-Unternehmensausschuss gemeinsam ihre Geschäftspolitik.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Das Bundeskartellamt[43] betrachtet Aldi Nord und Aldi Süd als „faktischen Gleichordnungskonzern“ im Sinne von § 18 Abs.\n",
      "aus Dokument:  Ampelkoalition\n",
      "Übereinstimmung:  0.99920845\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0. 0. 0. 0.99920845 0.]\n",
      "max:  0.99920845 position:  4\n",
      "----------------------------------------------\n",
      "Rechtlich, organisatorisch und seit 1966 auch finanziell sind beide Unternehmensgruppen völlig unabhängig voneinander.\n",
      "aus Dokument:  Ampelkoalition\n",
      "Übereinstimmung:  0.99920845\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0. 0. 0. 0.99920845 0.]\n",
      "max:  0.99920845 position:  4\n",
      "----------------------------------------------\n",
      "4250 Aldi-Filialen kontrollieren (Stand: April 2015).\n",
      "aus Dokument:  Al Pacino\n",
      "Übereinstimmung:  0.8645479\n",
      "  \n",
      "Mehr Infos:\n",
      "[0.8645479  0.02220994 0. 0. 0.02060394 0.]\n",
      "max:  0.8645479 position:  0\n",
      "----------------------------------------------\n",
      "Alfredo James „Al“ Pacino (* 25.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "April 1940 in New York) ist ein US-amerikanischer Schauspieler, Filmregisseur und Filmproduzent.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.97128874\n",
      "  \n",
      "Mehr Infos:\n",
      "[0.26235533 0.97128874 0. 0. 0.02156158 0.]\n",
      "max:  0.97128874 position:  1\n",
      "----------------------------------------------\n",
      "Er gilt für viele Kritiker und Zuschauer als einer der herausragenden Charakterdarsteller des zeitgenössischen amerikanischen Films und Theaters.\n",
      "aus Dokument:  Al Pacino\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[1. 0.02568966 0. 0. 0.02383204 0.]\n",
      "max:  1.0 position:  0\n",
      "----------------------------------------------\n",
      "So ist er seit den 1970er Jahren in zahlreichen Filmklassikern zu sehen.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "m Laufe seiner Karriere wurde er unter anderem mit dem Oscar, dem Golden Globe Award, dem Tony Award und der National Medal of Arts ausgezeichnet.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.9776011\n",
      "  \n",
      "Mehr Infos:\n",
      "[0.23502709 0.9776011  0. 0. 0.02102163 0.]\n",
      "max:  0.9776011 position:  1\n",
      "----------------------------------------------\n",
      "Pacino interessierte sich schon als Kind für die Schauspielerei.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Er verfeinerte sein Talent an zwei renommierten New Yorker Schauspielschulen, in Herbert Berghofs HB Studio und später bei Lee Strasberg im The Actors Studio.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.9443836\n",
      "  \n",
      "Mehr Infos:\n",
      "[0.3527114  0.9443836  0. 0. 0.02325108 0.]\n",
      "max:  0.9443836 position:  1\n",
      "----------------------------------------------\n",
      "Dort spielte er in mehreren erfolgreichen Theaterstücken wie in seinem Debütstück The Connection und in The Indian Wants the Bronx, für das er mit einem Obie-Award ausgezeichnet wurde.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.9986909\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.9986909  0. 0. 0.05756323 0.]\n",
      "max:  0.9986909 position:  1\n",
      "----------------------------------------------\n",
      "Al Pacino war insgesamt neun Mal für einen Oscar nominiert.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Seine erste Nominierung erhielt er 1973 für seine Rolle des Michael Corleone in Der Pate von Francis Ford Coppola.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Juni 1975 als Angelina Jolie Voight in Los Angeles, Kalifornien) ist eine US-amerikanisch-kambodschanische Schauspielerin, Filmregisseurin, Filmproduzentin und Drehbuchautorin.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.90377885\n",
      "  \n",
      "Mehr Infos:\n",
      "[0.45087582 0.90377885 0. 0. 0.02490604 0.]\n",
      "max:  0.90377885 position:  1\n",
      "----------------------------------------------\n",
      "Während ihrer Ehe mit Brad Pitt trug sie den Namen Angelina Jolie Pitt.\n",
      "aus Dokument:  Al Pacino\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[1. 0.02568966 0. 0. 0.02383204 0.]\n",
      "max:  1.0 position:  0\n",
      "----------------------------------------------\n",
      "Sie wurde mit der Darstellung der Videospielheldin Lara Croft in Lara Croft: Tomb Raider (2001) international bekannt.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "April 2000 bis zum 7.\n",
      "aus Dokument:  Al Pacino\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[1. 0.02568966 0. 0. 0.02383204 0.]\n",
      "max:  1.0 position:  0\n",
      "----------------------------------------------\n",
      "Dezember 2018 war sie CDU-Bundesvorsitzende.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Merkel wuchs in der DDR auf und war dort als Physikerin am Zentralinstitut für Physikalische Chemie tätig.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Dezember 1990 errang sie erstmals ein Bundestagsmandat.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n",
      "Nach dem knappen Sieg der Unionsparteien bei der vorgezogenen Bundestagswahl 2005 löste Merkel Gerhard Schröder als Bundeskanzler ab und führte zunächst eine große Koalition mit der SPD bis 2009 (Kabinett Merkel I).\n",
      "aus Dokument:  Al Pacino\n",
      "Übereinstimmung:  1.0\n",
      "  \n",
      "Mehr Infos:\n",
      "[1. 0.02568966 0. 0. 0.02383204 0.]\n",
      "max:  1.0 position:  0\n",
      "----------------------------------------------\n",
      "Oktober 2018 gab sie bekannt, zur Bundestagswahl 2021 nicht mehr zu kandidieren.\n",
      "aus Dokument:  Angelina Jolie\n",
      "Übereinstimmung:  0.99956226\n",
      "  \n",
      "Mehr Infos:\n",
      "[0. 0.99956226 0. 0. 0.01586484 0.]\n",
      "max:  0.99956226 position:  1\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for elm in list(enumerate(sim_hits)):\n",
    "    title = hit_title[np.argmax(elm[1])]\n",
    "    \n",
    "    if elm[1][np.argmax(elm[1])] > 0.80:\n",
    "        print(test_doc_raw_sentence[elm[0]])\n",
    "        print(\"aus Dokument: \", title)\n",
    "        print(\"Übereinstimmung: \", elm[1][np.argmax(elm[1])])\n",
    "        print(\"  \")\n",
    "        print(\"Mehr Infos:\")\n",
    "        print(str(elm[1]).replace(\"         \", \" \").replace(\"        \", \"\"))\n",
    "        print(\"max: \", elm[1][np.argmax(elm[1])], \"position: \", np.argmax(elm[1]))\n",
    "        print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates result tags for html output\n",
    "hit_result_html = \"\"\n",
    "hit_vis = []\n",
    "hits = 0\n",
    "for elm in list(enumerate(sim_hits)):\n",
    "    title = hit_title[np.argmax(elm[1])]\n",
    "    if elm[1][np.argmax(elm[1])] < 0.60:\n",
    "        cr_level=\"zero\"\n",
    "    if elm[1][np.argmax(elm[1])] >= 0.93:\n",
    "        cr_level=\"low\"\n",
    "    if elm[1][np.argmax(elm[1])] >= 0.95:\n",
    "        cr_level=\"medium\"\n",
    "    if elm[1][np.argmax(elm[1])] >= 0.98:\n",
    "        cr_level=\"higher\"\n",
    "    if elm[1][np.argmax(elm[1])] >= 0.99:\n",
    "        cr_level=\"high\"\n",
    "    \n",
    "    if cr_level==\"zero\":\n",
    "        hit_result_html = hit_result_html+\" <t class='\"+cr_level+\"'>\"+test_doc_raw_sentence[elm[0]]+\"</t> \"\n",
    "    else:\n",
    "        hit_result_html = hit_result_html+\" <t class='\"+cr_level+\"'>\"+test_doc_raw_sentence[elm[0]]+\"<b> <a href='https://de.wikipedia.org/wiki/\"+title+\"'>\"+title+\"</a></b></t>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".high {background-color: #F8E0E0;}\n",
       ".higher {background-color: #F8ECE0;}\n",
       ".medium {background-color: #F7F8E0;}\n",
       ".low {background-color: #E0F8E0;}\n",
       ".zero {background-color: white;}\n",
       "</style>\n",
       "\n",
       "   <t class='zero'>Gegenüber seinen Rivalen Aldi Süd und Lidl drohte Aldi Nord immer weiter zurückzufallen.</t>  <t class='zero'>„Viele Jahre hatte der Discounter zu wenig in die Modernisierung investiert und zu spät auf neue Trends reagiert.“[30] Daher führte die Aldi-Nord-Gruppe mit dem Aldi Nord Instore Konzept (ANIKo) ebenfalls ein „Modernisierungsprogramm“ durch.</t>  <t class='zero'>Insgesamt wurde die bis Anfang 2019 vorgesehene Umgestaltung der 2250 Aldi-Nord-Filialen auf 5,2 Milliarden Euro kalkuliert.</t>  <t class='high'>Im Anschluss erfolgte die Umgestaltung der rund 2400 Märkte im europäischen Ausland.<b> <a href='https://de.wikipedia.org/wiki/Angela Merkel'>Angela Merkel</a></b></t> <t class='zero'>Da keine expliziten Kostensenkungsprogramme bekannt sind, werden nach Beobachtern die Umbaukosten nur durch den später erwarteten höheren Umsatz wieder ausgeglichen.</t>  <t class='zero'>[31] Das Standardsortiment von Aldi Nord lag im Geschäftsjahr 2017 bei rund 1400 Artikeln.</t>  <t class='zero'>Der Test mit diesen Albrecht-Supermärkten scheiterte, da er weder in den Ladengrößen noch in der Sortimentsvielfalt der inzwischen davongeeilten Vollsortimenter-Konkurrenz ebenbürtig war.</t>  <t class='high'>Diese noch unter dem roten Albrecht-Logo getesteten Märkte wurden bald wieder geschlossen bzw.<b> <a href='https://de.wikipedia.org/wiki/Ampelkoalition'>Ampelkoalition</a></b></t> <t class='high'>konnten kurze Zeit später nach Umgestaltung auf Aldi-Discount genutzt werden.<b> <a href='https://de.wikipedia.org/wiki/Angela Merkel'>Angela Merkel</a></b></t> <t class='high'>Die beiden Unternehmensgruppen sind freundschaftlich verbunden und koordinieren im Aldi-Unternehmensausschuss gemeinsam ihre Geschäftspolitik.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Das Bundeskartellamt[43] betrachtet Aldi Nord und Aldi Süd als „faktischen Gleichordnungskonzern“ im Sinne von § 18 Abs.<b> <a href='https://de.wikipedia.org/wiki/Ampelkoalition'>Ampelkoalition</a></b></t> <t class='zero'>2 Aktiengesetz (Deutschland).</t>  <t class='high'>Rechtlich, organisatorisch und seit 1966 auch finanziell sind beide Unternehmensgruppen völlig unabhängig voneinander.<b> <a href='https://de.wikipedia.org/wiki/Ampelkoalition'>Ampelkoalition</a></b></t> <t class='zero'>In Deutschland umfassen Aldi Nord und Aldi Süd zusammen 66 Regionalgesellschaften, die wiederum ca.</t>  <t class='zero'>4250 Aldi-Filialen kontrollieren (Stand: April 2015).</t>  <t class='zero'>Die Regionalgesellschaften haben ihren Sitz oft außerhalb der größeren Ballungszentren; sie liegen meist nahe einem Autobahnanschluss, um die Effizienz der Belieferung der Filialen per Lkw zu erhöhen.</t>  <t class='high'>Alfredo James „Al“ Pacino (* 25.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='medium'>April 1940 in New York) ist ein US-amerikanischer Schauspieler, Filmregisseur und Filmproduzent.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Er gilt für viele Kritiker und Zuschauer als einer der herausragenden Charakterdarsteller des zeitgenössischen amerikanischen Films und Theaters.<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='high'>So ist er seit den 1970er Jahren in zahlreichen Filmklassikern zu sehen.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='medium'>m Laufe seiner Karriere wurde er unter anderem mit dem Oscar, dem Golden Globe Award, dem Tony Award und der National Medal of Arts ausgezeichnet.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='medium'>Seine bekanntesten Rollen sind die des Michael Corleone in der von Francis Ford Coppola inszenierten Der Pate-Trilogie und als Gangster Tony Montana in Scarface.<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='high'>Pacino interessierte sich schon als Kind für die Schauspielerei.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='low'>Er verfeinerte sein Talent an zwei renommierten New Yorker Schauspielschulen, in Herbert Berghofs HB Studio und später bei Lee Strasberg im The Actors Studio.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Dort spielte er in mehreren erfolgreichen Theaterstücken wie in seinem Debütstück The Connection und in The Indian Wants the Bronx, für das er mit einem Obie-Award ausgezeichnet wurde.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Al Pacino war insgesamt neun Mal für einen Oscar nominiert.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Seine erste Nominierung erhielt er 1973 für seine Rolle des Michael Corleone in Der Pate von Francis Ford Coppola.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='zero'>Angelina Jolie (* 4.</t>  <t class='zero'>Juni 1975 als Angelina Jolie Voight in Los Angeles, Kalifornien) ist eine US-amerikanisch-kambodschanische Schauspielerin, Filmregisseurin, Filmproduzentin und Drehbuchautorin.</t>  <t class='high'>Während ihrer Ehe mit Brad Pitt trug sie den Namen Angelina Jolie Pitt.<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='high'>Sie wurde mit der Darstellung der Videospielheldin Lara Croft in Lara Croft: Tomb Raider (2001) international bekannt.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='zero'>Angela Merkel (2019) Merkels Unterschrift\n",
       "Angela[1] Dorothea Merkel (geb.</t>  <t class='zero'>Kasner;[2] * 17.</t>  <t class='zero'>Juli 1954 in Hamburg) ist eine deutsche Politikerin (CDU).</t>  <t class='zero'>Sie ist seit dem 22.</t>  <t class='zero'>November 2005 Bundeskanzlerin der Bundesrepublik Deutschland.</t>  <t class='zero'>Vom 10.</t>  <t class='high'>April 2000 bis zum 7.<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='high'>Dezember 2018 war sie CDU-Bundesvorsitzende.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Merkel wuchs in der DDR auf und war dort als Physikerin am Zentralinstitut für Physikalische Chemie tätig.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='zero'>Bei der Bundestagswahl am 2.</t>  <t class='high'>Dezember 1990 errang sie erstmals ein Bundestagsmandat.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='high'>Bei den folgenden sieben Bundestagswahlen wurde sie in ihrem Wahlkreis in Vorpommern direkt gewählt.<b> <a href='https://de.wikipedia.org/wiki/Ampelkoalition'>Ampelkoalition</a></b></t> <t class='high'>[3] Von 1991 bis 1994 war Merkel Bundesministerin für Frauen und Jugend im Kabinett Kohl IV und von 1994 bis 1998 Bundesministerin für Umwelt, Naturschutz und Reaktorsicherheit im Kabinett Kohl V. 1998 bis zu ihrer Wahl zur Bundesvorsitzenden der Partei amtierte sie als Generalsekretärin der CDU.<b> <a href='https://de.wikipedia.org/wiki/Angela Merkel'>Angela Merkel</a></b></t> <t class='high'>Nach dem knappen Sieg der Unionsparteien bei der vorgezogenen Bundestagswahl 2005 löste Merkel Gerhard Schröder als Bundeskanzler ab und führte zunächst eine große Koalition mit der SPD bis 2009 (Kabinett Merkel I).<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='high'>Nach der Bundestagswahl 2009 ging sie mit der FDP eine schwarz-gelbe Koalition ein (Kabinett Merkel II), der 2013 eine erneute große Koalition folgte, die auch nach der Bundestagswahl 2017 fortgesetzt wird (Kabinett Merkel III und IV).<b> <a href='https://de.wikipedia.org/wiki/Al Pacino'>Al Pacino</a></b></t> <t class='zero'>Am 29.</t>  <t class='high'>Oktober 2018 gab sie bekannt, zur Bundestagswahl 2021 nicht mehr zu kandidieren.<b> <a href='https://de.wikipedia.org/wiki/Angelina Jolie'>Angelina Jolie</a></b></t> <t class='zero'>[4]</t> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# html output of all results\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".high {background-color: #F8E0E0;}\n",
    ".higher {background-color: #F8ECE0;}\n",
    ".medium {background-color: #F7F8E0;}\n",
    ".low {background-color: #E0F8E0;}\n",
    ".zero {background-color: white;}\n",
    "</style>\n",
    "\n",
    "  \"\"\"+hit_result_html+\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
