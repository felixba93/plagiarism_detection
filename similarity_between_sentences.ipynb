{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "include plagiarism_detection_master.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>similarity between sentences</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hit-corpus\n",
    "# takes all plagiarism documents with similarity over 0.75\n",
    "# split into sentences with spacy\n",
    "class MyCorpus_hits:\n",
    "    def __iter__(self):\n",
    "          for ids in enumerate(sims):\n",
    "            if ids[1] >= 0.75:\n",
    "                for split in spacy_data(texts[ids[0]]).sents:\n",
    "                    yield dictionary.doc2bow(preprocess_text(str(split)))\n",
    "                    elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_corpus = MyCorpus_hits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 1.57 s, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hit_lda = LdaMulticore(hit_corpus, num_topics=150, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.3 s, sys: 622 ms, total: 46.9 s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_hit_index = similarities.MatrixSimilarity(list(hit_lda[hit_corpus]), num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice test document to sentences\n",
    "test_doc_raw_slice = []\n",
    "for split in spacy_data(test_document).sents:\n",
    "    test_doc_raw_slice.append(preprocess_text(str(split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test doc Sätze vs hit_corpus \n",
    "# vergeleich nimmt eine listen ??\n",
    "test_doc_raw = test_doc_raw_slice\n",
    "test_vec = dictionary.doc2bow(test_doc_raw)\n",
    "#print(test_vec)\n",
    "# convert to lda space\n",
    "test_vec_lda = lda[test_vec]\n",
    "#print(test_vec_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hits for all sentences\n",
    "sims_hits = corpus_hit_index[test_vec_lda]\n",
    "print(list(enumerate(sims_hits)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hits = 0\n",
    "for ids in list(enumerate(sims_hits)):\n",
    "    if ids[1] > 0.03:\n",
    "        hits += 1\n",
    "        print(\"Document sentence:\",ids[0],\"%.2f\" %(ids[1]*100),\"%\",\"\\n\", \"------------------------------------\")\n",
    "        print(test_doc_raw_slice[ids[0]])\n",
    "print(hits, \"Plagiatsfälle gefunden\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
